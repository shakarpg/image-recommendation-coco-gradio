# Instalação das dependências (execute a primeira célula)
!pip install tensorflow tensorflow_hub numpy scikit-learn matplotlib gradio opencv-python --quiet

import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import matplotlib.pyplot as plt
import gradio as gr
import cv2
import os
from sklearn.neighbors import NearestNeighbors
from urllib.request import urlretrieve
import zipfile

print("TensorFlow version:", tf.__version__)

# Baixar e preparar o dataset COCO128 (subconjunto COCO)
if not os.path.exists("coco128.zip"):
    print("Baixando COCO128...")
    urlretrieve("https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip", "coco128.zip")

if not os.path.exists("coco128"):
    with zipfile.ZipFile("coco128.zip", 'r') as zip_ref:
        zip_ref.extractall(".")

# Listar imagens para usar na busca
img_dir = "coco128/images/train"
img_paths = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith(".jpg")]

# Carregar modelo TF Hub para embeddings (MobileNetV2 feature vector)
print("Carregando modelo TensorFlow Hub para embeddings...")
model_url = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"
embed_model = hub.KerasLayer(model_url, input_shape=(224,224,3), trainable=False)

def preprocess_image(img_path):
    img = tf.io.read_file(img_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, (224,224))
    img = img / 255.0
    return img

# Extrair embeddings para todas as imagens do dataset
print("Extraindo embeddings do dataset...")
dataset_imgs = []
for p in img_paths:
    img = preprocess_image(p)
    dataset_imgs.append(img)
dataset_imgs = tf.stack(dataset_imgs, axis=0)
embeddings = embed_model(dataset_imgs).numpy()

# Criar índice para busca com k-NN
nbrs = NearestNeighbors(n_neighbors=5, algorithm='auto', metric='cosine').fit(embeddings)

def find_similar(img_input, top_k=5):
    # img_input: numpy array RGB uint8
    img = cv2.resize(img_input, (224,224))
    img = img.astype(np.float32) / 255.0
    img = np.expand_dims(img, axis=0)
    emb = embed_model(img).numpy()
    distances, indices = nbrs.kneighbors(emb, n_neighbors=top_k)
    results = []
    for idx in indices[0]:
        path = img_paths[idx]
        results.append(path)
    return results

def show_results(input_img):
    # input_img: numpy array RGB uint8 (from Gradio)
    similar_paths = find_similar(input_img)
    imgs = [plt.imread(p) for p in similar_paths]
    return imgs

# Interface Gradio
iface = gr.Interface(
    fn=show_results,
    inputs=gr.Image(type="numpy"),
    outputs=gr.Gallery(label="Imagens similares"),
    title="Sistema de Recomendação por Imagens - COCO128 + Gradio",
    description="Envie uma imagem para encontrar produtos similares baseados em aparência."
)

iface.launch()
